---
title: "Take-home Exercise 1: "
author: "QIU RUILIU"
date: "26 Nov 2023"
date-modified: "last-modified"
format: html
execute: 
  eval: true
  echo: true
  warning: false
editor: visual
---

## **Setting the Scene**

In modern cities, digital transformations in transportation and public utilities, including buses, taxis, mass transit, and roads, generate extensive datasets. These datasets can track patterns of movement over time and space, especially with the widespread integration of technologies like GPS and RFID in vehicles. For instance, smart cards and GPS devices on public buses help gather data on routes and ridership. The vast amount of movement data thus collected likely reveals structural patterns and useful insights about the observed phenomena. Analyzing and comparing these patterns can offer deeper understanding of human movements and behaviors within urban environments. Such insights are valuable for enhancing city management and providing key information to both private and public urban transport service providers, aiding them in making informed decisions for a competitive edge.

However, in practical applications, the utilization of this extensive location-aware data is often limited to basic tracking and mapping using GIS (Geographic Information System) tools. This limitation stems mainly from the inadequate capabilities of traditional GIS in effectively analyzing and modeling spatial and spatio-temporal data.

## Objectives

-   Apply Exploratory Spatial Data Analysis (ESDA) to uncover spatial and spatio-temporal mobility patterns of public bus passengers in Singapore.

-   Utilize Local Indicators of Spatial Association (LISA) and Emerging Hot Spot Analysis (EHSA) for this analysis.

## Tasks

### Geovisualisation and Analysis

-   Compute passenger trips from origin at the hexagon level during different peak hours

| Peak hour period             | Bus tap on time |
|------------------------------|-----------------|
| Weekday morning peak         | 6am to 9am      |
| Weekday afternoon peak       | 5pm to 8pm      |
| Weekend/holiday morning peak | 11am to 2pm     |
| Weekend/holiday evening peak | 4pm to 7pm      |

-   Use appropriate geovisualisation methods to display geographical distribution of these trips.

-   Describe spatial patterns observed in the geovisualisations (max 200 words per visual).

### Local Indicators of Spatial Association (LISA) Analysis

-   Calculate LISA for passenger trips by origin at hexagon level.

-   Display LISA maps for these trips, highlighting only significant results (p-value \< 0.05).

-   Draw statistical conclusions based on the analysis results (max 200 words per visual).

### Emerging Hot Spot Analysis (EHSA)

-   Conduct Mann-Kendall Test using spatio-temporal local Gi\* values for passenger trips by origin at the hexagon level for the four time intervals.

-   Prepare EHSA maps showing Gi\* values of passenger trips by origin at hexagon level, focusing on significant results (p-value \< 0.05).

-   Describe spatial patterns revealed in EHSA maps and data visualisation (max 250 words per cluster).

## Getting Started

## **Installing and Loading the R Packages**

As usual, `p_load()` of **pacman** package will be used to check if the necessary packages have been installed in R, if yes, load the packages on R environment.

Five R packages are need for this take-home exercise, they are: sf, sfdep, tmap, plotly and tidyverse.

```{r}
pacman::p_load(sf, dplyr, sfdep, spdep, mapview, tmap, plotly, tidyverse, knitr, ggplot2, spacetime, lubridate)
```

## **The Data**

### Aspatial Data

-   *Passenger Volume by Origin Destination Bus Stops* from LTA DataMall. In this exercise, we will focus on the latest data which is the Octmber of 2023.

```{r}
    odbus <- read_csv("data/aspatial/origin_destination_bus_202310.csv")
```

```{r}
glimpse(odbus)
```

```{r}
odbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE)
odbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE)
```

Notice that both of them are in factor data type now.

```{r}
glimpse(odbus)
```

## **Extract Commuting Flow data**

For the **Weekday morning peak** (6am to 9am):

```{r}
weekday_morning_peak <- odbus %>%
  filter(DAY_TYPE == "WEEKDAY") %>%
  filter(TIME_PER_HOUR >= 6 & TIME_PER_HOUR <= 9) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%
  mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS))
```

```{r}
kable(head(weekday_morning_peak))
```

For the **Weekday afternoon peak** (5pm to 8pm):

```{r}
weekday_afternoon_peak <- odbus %>%
  filter(DAY_TYPE == "WEEKDAY") %>%
  filter(TIME_PER_HOUR >= 17 & TIME_PER_HOUR <= 20) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%
  mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS))
```

```{r}
kable(head(weekday_afternoon_peak))
```

For the **Weekend/holiday morning peak** (11am to 2pm):

```{r}
weekend_morning_peak <- odbus %>%
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  filter(TIME_PER_HOUR >= 11 & TIME_PER_HOUR <= 14) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%
  mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS))
```

```{r}
kable(head(weekend_morning_peak))
```

For the **Weekend/holiday evening peak** (4pm to 7pm):

```{r}
weekend_evening_peak <- odbus %>%
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  filter(TIME_PER_HOUR >= 16 & TIME_PER_HOUR <= 19) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%
  mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS))
```

```{r}
kable(head(weekend_evening_peak))
```

Create the trips by hour for each origin stop in weekdays

```{r}
weekday_trips <- odbus %>%
  filter(DAY_TYPE == "WEEKDAY") %>%
  group_by(ORIGIN_PT_CODE, TIME_PER_HOUR) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS, na.rm = TRUE)) %>%
  mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS))
```

```{r}
weekend_trips <- odbus %>%
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  group_by(ORIGIN_PT_CODE, TIME_PER_HOUR) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS, na.rm = TRUE)) %>%
  mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS))
```

Remove unnecessary dataset **odbus** in R environment to avoid redundancy

```{r}
rm(odbus)
```

### Geospatial Data

-   *Bus Stop Location* from LTA DataMall: Contains information on all bus stops serviced by buses, including bus stop codes and location coordinates.

```{r}
    busstop <- st_read(dsn = "data/geospatial",
                       layer = "BusStop") %>%
      st_transform(crs = 3414)
```

```{r}
mapview(busstop)
```

## Creating the Hexagon Layer

Create hexagonal grid over the extent of the bus stops with a diameter of around 577.35m for each hexagon

```{r}
hex_grid <- st_make_grid(busstop, cellsize = (4/3)*sqrt(3)*250, square = FALSE)
```

Convert the hexagonal grid to an sf object and create a unique ID for each hexagon

```{r}
hex_grid_sf <- st_sf(geometry = hex_grid) %>%
  mutate(hex_id = 1:length(hex_grid))
```

To count the number of bus stops in each hexagon, use st_intersects

```{r}
hex_grid_sf$bus_stop_count <- lengths(st_intersects(hex_grid_sf, busstop))
```

Remove hexagons with 0 bus stops to clean up the visualization

```{r}
hex_grid_sf <- filter(hex_grid_sf, bus_stop_count > 0)
```

visualize the hexagon grid with the count of bus stops

```{r}
tmap_mode("view")

map_hexagon <- tm_shape(hex_grid_sf) +
  tm_fill(
    col = "bus_stop_count",
    palette = "Blues",
    style = "cont",
    title = "Number of Bus Stops",
    id = "hex_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.vars = c(
      "Number of Bus Stops: " = "bus_stop_count"
    ),
    popup.format = list(
      bus_stop_count = list(format = "f", digits = 0)
    )
  ) +
  tm_borders(col = "grey40", lwd = 0.7) +
  tm_layout(legend.position = c("left", "bottom"))

map_hexagon
```

Remove unnecessary dataset **hex_grid map_hexagon** in R environment to avoid redundancy

```{r}
st_write(hex_grid_sf, "data/geospatial/hex_layer.shp", append = FALSE)
```

```{r}
rm(map_hexagon, hex_grid)
```

## Combine Passenger Trips and Hexagon Layer

### Weekday Morning Peak

First, perform a spatial join to match bus stops to the hexagon grid cells they fall into

```{r}
busstop_hex <- st_join(busstop, hex_grid_sf)
```

Then, join the passenger trips data with the busstop_hex data

```{r}
weekday_morning_trips <- busstop_hex %>%
  inner_join(weekday_morning_peak, by = c("BUS_STOP_N" = "ORIGIN_PT_CODE"))
```

Check for duplicates

```{r}
duplicate <- weekday_morning_trips %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
glimpse(duplicate)
```

Aggregate trip data by hexagon grid cells

```{r}
hex_weekday_morning <- weekday_morning_trips %>%
  group_by(hex_id) %>%
  summarise(weekday_morning_trips = sum(TRIPS, na.rm = TRUE)) %>%
  mutate(weekday_morning_trips = ifelse(is.na(weekday_morning_trips), 0, weekday_morning_trips))
```

Merge the trip summary data back into the hexagon grid data frame

```{r}
# Remove the geometry column temporarily for the join
hex_weekday_morning_df <- hex_weekday_morning %>% 
  st_set_geometry(NULL)
# Perform the join using dplyr's left_join
hex_grid_sf <- hex_grid_sf %>%
  inner_join(hex_weekday_morning_df, by = "hex_id")
```

```{r}
tmap_mode("plot")
tm_shape(hex_grid_sf) +
  tm_fill("weekday_morning_trips", 
          style = "quantile", 
          palette = "Blues",
          title = "Passenger trips") +
  tm_layout(main.title = "Weekday Morning Peak Passenger Trips",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2) +
  tm_credits("Source: LTA DataMall", position = c("left", "bottom"))
```

### Weekday Afternoon Peak

```{r}
weekday_afternoon_trips <- busstop_hex %>%
  inner_join(weekday_afternoon_peak, by = c("BUS_STOP_N" = "ORIGIN_PT_CODE"))
```

Check duplicates

```{r}
duplicate <- weekday_morning_trips %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
glimpse(duplicate)
```

Aggregate trip data by hexagon grid cells

```{r}
hex_weekday_afternoon <- weekday_afternoon_trips %>%
  group_by(hex_id) %>%
  summarise(weekday_afternoon_trips = sum(TRIPS, na.rm = TRUE)) %>%
  mutate(weekday_afternoon_trips = ifelse(is.na(weekday_afternoon_trips), 0, weekday_afternoon_trips))
```

Merge the trip summary data back into the hexagon grid data frame

```{r}
# Remove the geometry column temporarily for the join
hex_weekday_afternoon_df <- hex_weekday_afternoon %>% 
  st_set_geometry(NULL)

# Perform the join using dplyr's left_join
hex_grid_sf <- hex_grid_sf %>%
  inner_join(hex_weekday_afternoon_df, by = "hex_id")
```

```{r}
tm_shape(hex_grid_sf) +
  tm_fill("weekday_afternoon_trips", 
          style = "quantile", 
          palette = "Blues",
          title = "Passenger trips") +
  tm_layout(main.title = "Weekday Afternoon Peak Passenger Trips",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2) +
  tm_credits("Source: LTA DataMall", position = c("left", "bottom"))
```

### Weekend Morning Peak

```{r}
weekend_morning_trips <- busstop_hex %>%
  inner_join(weekend_morning_peak, by = c("BUS_STOP_N" = "ORIGIN_PT_CODE"))
```

```{r}
duplicate <- weekend_morning_trips %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
glimpse(duplicate)
```

```{r}
hex_weekend_morning <- weekend_morning_trips %>%
  group_by(hex_id) %>%
  summarise(weekend_morning_trips = sum(TRIPS, na.rm = TRUE)) %>%
  mutate(weekend_morning_trips = ifelse(is.na(weekend_morning_trips), 0, weekend_morning_trips))
```

```{r}
# Remove the geometry column temporarily for the join
hex_weekend_morning_df <- hex_weekend_morning %>% 
  st_set_geometry(NULL)

# Perform the join using dplyr's left_join
hex_grid_sf <- hex_grid_sf %>%
  inner_join(hex_weekend_morning_df, by = "hex_id")
```

```{r}
tm_shape(hex_grid_sf) +
  tm_fill("weekend_morning_trips", 
          style = "quantile", 
          palette = "Blues",
          title = "Passenger trips") +
  tm_layout(main.title = "Weekend Morning Peak Passenger Trips",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2) +
  tm_credits("Source: LTA DataMall", position = c("left", "bottom"))
```

### Weekend Evening Peak

```{r}
weekend_evening_trips <- busstop_hex %>%
  inner_join(weekend_evening_peak, by = c("BUS_STOP_N" = "ORIGIN_PT_CODE"))
```

```{r}
duplicate <- weekend_evening_trips %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
glimpse(duplicate)
```

```{r}
hex_weekend_evening <- weekend_evening_trips %>%
  group_by(hex_id) %>%
  summarise(weekend_evening_trips = sum(TRIPS, na.rm = TRUE)) %>%
  mutate(weekend_evening_trips = ifelse(is.na(weekend_evening_trips), 0, weekend_evening_trips))
```

```{r}
# Remove the geometry column temporarily for the join
hex_weekend_evening_df <- hex_weekend_evening %>% 
  st_set_geometry(NULL)

# Perform the join using dplyr's left_join
hex_grid_sf <- hex_grid_sf %>%
  inner_join(hex_weekend_evening_df, by = "hex_id")
```

```{r}
tm_shape(hex_grid_sf) +
  tm_fill("weekend_evening_trips", 
          style = "quantile", 
          palette = "Blues",
          title = "Passenger trips") +
  tm_layout(main.title = "Weekend Evening Peak Passenger Trips",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2) +
  tm_credits("Source: LTA DataMall", position = c("left", "bottom"))
```

```{r}
rm(hex_weekday_afternoon, hex_weekday_morning, hex_weekend_evening, hex_weekend_morning, hex_weekday_afternoon_df, hex_weekday_morning_df, hex_weekend_evening_df, hex_weekend_morning_df, weekday_afternoon_peak, weekday_afternoon_trips, weekday_morning_peak, weekday_morning_trips, weekend_evening_peak, weekend_evening_trips, weekend_morning_peak, weekend_morning_trips)
```

## **Global Measures of Spatial Association**

### **Deriving fixed distance weights**

```{r}
geo <- sf::st_geometry(hex_grid_sf)
nb <- st_knn(geo, longlat = TRUE)
dists <- unlist(st_nb_dists(geo, nb))
```

```{r}
summary(dists)
```

```{r}
wm_fd <- hex_grid_sf %>%
  mutate(nb = st_dist_band(geometry,
                           upper = 4359),
               wt = st_weights(nb),
               .before = 1)
```

### **Deriving adaptive distance weights**

```{r}
wm_ad <- hex_grid_sf %>% 
  mutate(nb = st_knn(geometry,
                     k=6),
         wt = st_weights(nb),
               .before = 1)
```

### **Calculate inverse distance weights**

```{r}
wm_idw <- hex_grid_sf %>%
  mutate(nb = st_contiguity(geometry),
         wts = st_inverse_distance(nb, geometry,
                                   scale = 1,
                                   alpha = 1),
         .before = 1)
```

### **Performing Global Moran'sI test**

In general, Moran's I test will be performed instead of just computing the Moran's I statistics. With sfdep package, Moran's I test can be performed by using [`global_moran_test()`](https://sfdep.josiahparry.com/reference/global_moran_test.html) as shown in the code chunk below.

```{r}
global_moran_test(wm_idw$weekday_morning_trips,
                       wm_idw$nb,
                       wm_idw$wts,
                       zero.policy = TRUE)
```

```{r}
global_moran_test(wm_idw$weekday_afternoon_trips,
                       wm_idw$nb,
                       wm_idw$wts,
                       zero.policy = TRUE)
```

```{r}
global_moran_test(wm_idw$weekend_morning_trips,
                       wm_idw$nb,
                       wm_idw$wts,
                       zero.policy = TRUE)
```

```{r}
global_moran_test(wm_idw$weekend_evening_trips,
                       wm_idw$nb,
                       wm_idw$wts,
                       zero.policy = TRUE)
```

### **Performing Global Moran'I permutation test**

It is always a good practice to use `set.seed()` before performing simulation. This is to ensure that the computation is reproducible.

```{r}
set.seed(1234)
```

Next, `global_moran_perm()` is used to perform Monte Carlo simulation.

```{r}
global_moran_perm(wm_idw$weekday_morning_trips,
                       wm_idw$nb,
                       wm_idw$wts,
                       zero.policy = TRUE,
                  nsim = 99)
```

```{r}
global_moran_perm(wm_idw$weekday_afternoon_trips,
                       wm_idw$nb,
                       wm_idw$wts,
                       zero.policy = TRUE,
                  nsim = 99)
```

```{r}
global_moran_perm(wm_idw$weekend_morning_trips,
                       wm_idw$nb,
                       wm_idw$wts,
                       zero.policy = TRUE,
                  nsim = 99)
```

```{r}
global_moran_perm(wm_idw$weekend_evening_trips,
                       wm_idw$nb,
                       wm_idw$wts,
                       zero.policy = TRUE,
                  nsim = 99)
```

## **Compute and Visualize local Moran's I**

```{r}
lisa_wdm <- wm_idw %>% 
  mutate(local_moran = local_moran(
    weekday_morning_trips, nb, wts, nsim = 99, zero.policy = TRUE),
         .before = 1) %>%
  unnest(local_moran)
```

```{r}
tmap_mode("plot")
map1 <- tm_shape(lisa_wdm) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of Weekday Morning Trips",
            main.title.size = 0.8)

map2 <- tm_shape(lisa_wdm) +
  tm_fill("p_ii_sim",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)
```

```{r}
lisa_wdm_sig <- lisa_wdm  %>%
  filter(p_ii_sim < 0.05)
tmap_mode("plot")
tm_shape(lisa_wdm) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_wdm_sig) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```

```{r}
lisa_wda <- wm_idw %>% 
  mutate(local_moran = local_moran(
    weekday_afternoon_trips, nb, wts, nsim = 99, zero.policy = TRUE),
         .before = 1) %>%
  unnest(local_moran)
```

```{r}
tmap_mode("plot")
map1 <- tm_shape(lisa_wda) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of Weekday Afternoon Trips",
            main.title.size = 0.8)

map2 <- tm_shape(lisa_wda) +
  tm_fill("p_ii_sim",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)
```

```{r}
lisa_wda_sig <- lisa_wda  %>%
  filter(p_ii_sim < 0.05)
tmap_mode("plot")
tm_shape(lisa_wda) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_wdm_sig) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```

```{r}
lisa_wem <- wm_idw %>% 
  mutate(local_moran = local_moran(
    weekend_morning_trips, nb, wts, nsim = 99, zero.policy = TRUE),
         .before = 1) %>%
  unnest(local_moran)
```

```{r}
tmap_mode("plot")
map1 <- tm_shape(lisa_wem) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of Weekend Morning Trips",
            main.title.size = 0.8)

map2 <- tm_shape(lisa_wem) +
  tm_fill("p_ii_sim",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)
```

```{r}
lisa_wem_sig <- lisa_wem  %>%
  filter(p_ii_sim < 0.05)
tmap_mode("plot")
tm_shape(lisa_wem) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_wem_sig) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```

```{r}
lisa_wee <- wm_idw %>% 
  mutate(local_moran = local_moran(
    weekend_evening_trips, nb, wts, nsim = 99, zero.policy = TRUE),
         .before = 1) %>%
  unnest(local_moran)
```

```{r}
tmap_mode("plot")
map1 <- tm_shape(lisa_wee) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of Weekend Evening Trips",
            main.title.size = 0.8)

map2 <- tm_shape(lisa_wee) +
  tm_fill("p_ii_sim",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)
```

```{r}
lisa_wee_sig <- lisa_wee  %>%
  filter(p_ii_sim < 0.05)
tmap_mode("plot")
tm_shape(lisa_wee) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_wee_sig) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```

```{r}
rm(lisa_wda, lisa_wda_sig, lisa_wdm, lisa_wdm_sig, lisa_wee, lisa_wee_sig, lisa_wem, lisa_wem_sig, map1, map2, nb, wm_ad, wm_fd, wm_idw, dists)
```

# **Emerging Hot Spot Analysis**

```{r}
# Create a complete set of hours for each ORIGIN_PT_CODE
hours <- data.frame(TIME_PER_HOUR = 0:23)
origin_pt_codes <- unique(weekday_trips$ORIGIN_PT_CODE)
complete_hours <- expand.grid(ORIGIN_PT_CODE = origin_pt_codes, TIME_PER_HOUR = hours$TIME_PER_HOUR)

# Merge the complete set of hours with the original data
# and replace NA values with zero
weekday_trips_complete <- merge(complete_hours, weekday_trips, by = c("ORIGIN_PT_CODE", "TIME_PER_HOUR"), all.x = TRUE)
weekday_trips_complete$TRIPS[is.na(weekday_trips_complete$TRIPS)] <- 0
```

```{r}
# Create a complete set of hours for each ORIGIN_PT_CODE
origin_pt_codes <- unique(weekend_trips$ORIGIN_PT_CODE)
complete_hours <- expand.grid(ORIGIN_PT_CODE = origin_pt_codes, TIME_PER_HOUR = hours$TIME_PER_HOUR)

# Merge the complete set of hours with the original data
# and replace NA values with zero
weekend_trips_complete <- merge(complete_hours, weekend_trips, by = c("ORIGIN_PT_CODE", "TIME_PER_HOUR"), all.x = TRUE)
weekend_trips_complete$TRIPS[is.na(weekend_trips_complete$TRIPS)] <- 0
```

```{r}
weekday_trips_hex <- busstop_hex %>%
  inner_join(weekday_trips_complete, by = c("BUS_STOP_N" = "ORIGIN_PT_CODE"))
```

```{r}
weekday_trips_summary <- weekday_trips_hex %>%
  group_by(hex_id, TIME_PER_HOUR) %>%
  summarise(total_trips = sum(TRIPS, na.rm = TRUE))
```

```{r}
# Create a complete set of hours for each ORIGIN_PT_CODE
origin_pt_codes <- unique(weekend_trips$ORIGIN_PT_CODE)
complete_hours <- expand.grid(ORIGIN_PT_CODE = origin_pt_codes, TIME_PER_HOUR = hours$TIME_PER_HOUR)

# Merge the complete set of hours with the original data
# and replace NA values with zero
weekend_trips_complete <- merge(complete_hours, weekend_trips, by = c("ORIGIN_PT_CODE", "TIME_PER_HOUR"), all.x = TRUE)
weekend_trips_complete$TRIPS[is.na(weekend_trips_complete$TRIPS)] <- 0
```

```{r}
weekend_trips_hex <- busstop_hex %>%
  inner_join(weekend_trips_complete, by = c("BUS_STOP_N" = "ORIGIN_PT_CODE"))
```

```{r}
weekend_trips_summary <- weekend_trips_hex %>%
  group_by(hex_id, TIME_PER_HOUR) %>%
  summarise(total_trips = sum(TRIPS, na.rm = TRUE))
```

```{r}
hex_grid_sf <- st_read(dsn = "data/geospatial", 
                 layer = "hex_layer")
```

# **Creating a Time Series Cube**

```{r}
weekday_trips_st <- as_spacetime(weekday_trips_summary, hex_grid_sf,
                      .loc_col = "hex_id",
                      .time_col = "TIME_PER_HOUR")
```

```{r}
is_spacetime_cube(weekday_trips_st)
```

```{r}
weekend_trips_st <- as_spacetime(weekend_trips_summary, hex_grid_sf,
                      .loc_col = "hex_id",
                      .time_col = "TIME_PER_HOUR")
```

```{r}
is_spacetime_cube(weekend_trips_st)
```

## Reference

<https://desktop.arcgis.com/zh-cn/arcmap/latest/tools/spatial-statistics-toolbox/h-whyhexagons.htm>

<https://urbandatapalette.com/post/2021-08-tessellation-sf/>
