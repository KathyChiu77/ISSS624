---
title: "Take-home Exercise 1: "
author: "QIU RUILIU"
date: "26 Nov 2023"
date-modified: "last-modified"
format: html
execute: 
  eval: true
  echo: true
  warning: false
editor: visual
---

## **Setting the Scene**

In modern cities, digital transformations in transportation and public utilities, including buses, taxis, mass transit, and roads, generate extensive datasets. These datasets can track patterns of movement over time and space, especially with the widespread integration of technologies like GPS and RFID in vehicles. For instance, smart cards and GPS devices on public buses help gather data on routes and ridership. The vast amount of movement data thus collected likely reveals structural patterns and useful insights about the observed phenomena. Analyzing and comparing these patterns can offer deeper understanding of human movements and behaviors within urban environments. Such insights are valuable for enhancing city management and providing key information to both private and public urban transport service providers, aiding them in making informed decisions for a competitive edge.

However, in practical applications, the utilization of this extensive location-aware data is often limited to basic tracking and mapping using GIS (Geographic Information System) tools. This limitation stems mainly from the inadequate capabilities of traditional GIS in effectively analyzing and modeling spatial and spatio-temporal data.

## Objectives

-   Apply Exploratory Spatial Data Analysis (ESDA) to uncover spatial and spatio-temporal mobility patterns of public bus passengers in Singapore.

-   Utilize Local Indicators of Spatial Association (LISA) and Emerging Hot Spot Analysis (EHSA) for this analysis.

## Tasks

### Geovisualisation and Analysis

-   Compute passenger trips from origin at the hexagon level during different peak hours

| Peak hour period             | Bus tap on time |
|------------------------------|-----------------|
| Weekday morning peak         | 6am to 9am      |
| Weekday afternoon peak       | 5pm to 8pm      |
| Weekend/holiday morning peak | 11am to 2pm     |
| Weekend/holiday evening peak | 4pm to 7pm      |

-   Use appropriate geovisualisation methods to display geographical distribution of these trips.

-   Describe spatial patterns observed in the geovisualisations (max 200 words per visual).

### Local Indicators of Spatial Association (LISA) Analysis

-   Calculate LISA for passenger trips by origin at hexagon level.

-   Display LISA maps for these trips, highlighting only significant results (p-value \< 0.05).

-   Draw statistical conclusions based on the analysis results (max 200 words per visual).

### Emerging Hot Spot Analysis (EHSA)

-   Conduct Mann-Kendall Test using spatio-temporal local Gi\* values for passenger trips by origin at the hexagon level for the four time intervals.

-   Prepare EHSA maps showing Gi\* values of passenger trips by origin at hexagon level, focusing on significant results (p-value \< 0.05).

-   Describe spatial patterns revealed in EHSA maps and data visualisation (max 250 words per cluster).

## Getting Started

## **Installing and Loading the R Packages**

As usual, `p_load()` of **pacman** package will be used to check if the necessary packages have been installed in R, if yes, load the packages on R environment.

Five R packages are need for this take-home exercise, they are: sf, sfdep, tmap, plotly and tidyverse.

```{r}
pacman::p_load(sf, dplyr, sfdep, spdep, mapview, tmap, plotly, tidyverse, knitr)
```

## **The Data**

### Aspatial Data

-   *Passenger Volume by Origin Destination Bus Stops* from LTA DataMall. In this exercise, we will focus on the latest data which is the Octmber of 2023.

```{r}
    odbus <- read_csv("data/aspatial/origin_destination_bus_202310.csv")
```

```{r}
glimpse(odbus)
```

```{r}
odbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE)
odbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE)
```

Notice that both of them are in factor data type now.

```{r}
glimpse(odbus)
```

## **Extract Commuting Flow data**

For the **Weekday morning peak** (6am to 9am):

```{r}
weekday_morning_peak <- odbus %>%
  filter(DAY_TYPE == "WEEKDAY") %>%
  filter(TIME_PER_HOUR >= 6 & TIME_PER_HOUR <= 9) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))
```

```{r}
kable(head(weekday_morning_peak))
```

We will save the output in rds format for future used.

```{r}
write_rds(weekday_morning_peak, "data/rds/weekday_morning_peak.rds")
```

The code chunk below will be used to import the save weekday_morning_peak.rds into R environment.

```{r}
weekday_morning_peak <- read_rds("data/rds/weekday_morning_peak.rds")
```

For the **Weekday afternoon peak** (5pm to 8pm):

```{r}
weekday_afternoon_peak <- odbus %>%
  filter(DAY_TYPE == "WEEKDAY") %>%
  filter(TIME_PER_HOUR >= 17 & TIME_PER_HOUR <= 20) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))
```

```{r}
kable(head(weekday_afternoon_peak))
```

We will save the output in rds format for future used.

```{r}
write_rds(weekday_afternoon_peak, "data/rds/weekday_afternoon_peak.rds")
```

The code chunk below will be used to import the save weekday_morning_peak.rds into R environment.

```{r}
weekday_afternoon_peak <- read_rds("data/rds/weekday_afternoon_peak.rds")
```

For the **Weekend/holiday morning peak** (11am to 2pm):

```{r}
weekend_morning_peak <- odbus %>%
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  filter(TIME_PER_HOUR >= 11 & TIME_PER_HOUR <= 14) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))
```

```{r}
kable(head(weekend_morning_peak))
```

We will save the output in rds format for future used.

```{r}
write_rds(weekend_morning_peak, "data/rds/weekend_morning_peak.rds")
```

The code chunk below will be used to import the save weekday_morning_peak.rds into R environment.

```{r}
weekend_morning_peak <- read_rds("data/rds/weekend_morning_peak.rds")
```

For the **Weekend/holiday evening peak** (4pm to 7pm):

```{r}
weekend_evening_peak <- odbus %>%
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  filter(TIME_PER_HOUR >= 16 & TIME_PER_HOUR <= 19) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))
```

```{r}
kable(head(weekend_evening_peak))
```

We will save the output in rds format for future used.

```{r}
write_rds(weekend_evening_peak, "data/rds/weekend_evening_peak.rds")
```

The code chunk below will be used to import the save weekday_morning_peak.rds into R environment.

```{r}
weekend_evening_peak <- read_rds("data/rds/weekend_evening_peak.rds")
```

Remove unnecessary dataset **odbus** in R environment to avoid redundancy

```{r}
rm(odbus)
```

### Geospatial Data

-   *Bus Stop Location* from LTA DataMall: Contains information on all bus stops serviced by buses, including bus stop codes and location coordinates.

```{r}
    busstop <- st_read(dsn = "data/geospatial",
                       layer = "BusStop") %>%
      st_transform(crs = 3414)
```

```{r}
mapview(busstop)
```

## Creating the Hexagon Layer

Create hexagonal grid over the extent of the bus stops with a diameter of around 577.35m for each hexagon

```{r}
hex_grid <- st_make_grid(busstop, cellsize = (4/3)*sqrt(3)*250, square = FALSE)
```

Convert the hexagonal grid to an sf object and create a unique ID for each hexagon

```{r}
hex_grid_sf <- st_sf(geometry = hex_grid) %>%
  mutate(hex_id = 1:length(hex_grid))
```

To count the number of bus stops in each hexagon, use st_intersects

```{r}
hex_grid_sf$bus_stop_count <- lengths(st_intersects(hex_grid_sf, busstop))
```

Remove hexagons with 0 bus stops to clean up the visualization

```{r}
hex_grid_sf <- filter(hex_grid_sf, bus_stop_count > 0)
```

visualize the hexagon grid with the count of bus stops

```{r}
tmap_mode("view")

map_hexagon <- tm_shape(hex_grid_sf) +
  tm_fill(
    col = "bus_stop_count",
    palette = "Blues",
    style = "cont",
    title = "Number of Bus Stops",
    id = "hex_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.vars = c(
      "Number of Bus Stops: " = "bus_stop_count"
    ),
    popup.format = list(
      bus_stop_count = list(format = "f", digits = 0)
    )
  ) +
  tm_borders(col = "grey40", lwd = 0.7) +
  tm_layout(legend.position = c("left", "bottom"))

map_hexagon
```

Remove unnecessary dataset **hex_grid map_hexagon** in R environment to avoid redundancy

```{r}
rm(hex_grid, map_hexagon)
```

## Combine Passenger Trips and Hexagon Layer

### Weekday Morning Peak

First, perform a spatial join to match bus stops to the hexagon grid cells they fall into

```{r}
busstop_hex <- st_join(busstop, hex_grid_sf)
```

Then, join the passenger trips data with the busstop_hex data

```{r}
weekday_morning_trips <- busstop_hex %>%
  inner_join(weekday_morning_peak, by = c("BUS_STOP_N" = "ORIGIN_PT_CODE"))
```

Check for duplicates

```{r}
duplicate <- weekday_morning_trips %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
glimpse(duplicate)
```

Aggregate trip data by hexagon grid cells

```{r}
hex_weekday_morning <- weekday_morning_trips %>%
  group_by(hex_id) %>%
  summarise(weekday_morning_trips = sum(TRIPS, na.rm = TRUE))
```

Merge the trip summary data back into the hexagon grid data frame

```{r}
hex_grid_sf <- hex_grid_sf %>%
    st_join(hex_weekday_morning, by = "hex_id")

hex_grid_sf <- hex_grid_sf %>%
  select(-hex_id.y) %>%
  rename(hex_id = hex_id.x)
```

```{r}
tmap_mode("plot")
tm_shape(hex_grid_sf) +
  tm_fill("weekday_morning_trips", 
          style = "quantile", 
          palette = "Blues",
          title = "Passenger trips") +
  tm_layout(main.title = "Weekday Morning Peak Passenger Trips",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2) +
  tm_credits("Source: LTA DataMall", position = c("left", "bottom"))
```

### Weekday Afternoon Peak

```{r}
weekday_afternoon_trips <- busstop_hex %>%
  inner_join(weekday_afternoon_peak, by = c("BUS_STOP_N" = "ORIGIN_PT_CODE"))
```

Check duplicates

```{r}
duplicate <- weekday_morning_trips %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
glimpse(duplicate)
```

Aggregate trip data by hexagon grid cells

```{r}
hex_weekday_afternoon <- weekday_afternoon_trips %>%
  group_by(hex_id) %>%
  summarise(weekday_afternoon_trips = sum(TRIPS, na.rm = TRUE))
```

Merge the trip summary data back into the hexagon grid data frame

```{r}
hex_grid_sf <- hex_grid_sf %>%
    st_join(hex_weekday_afternoon, by = "hex_id")

hex_grid_sf <- hex_grid_sf %>%
  select(-hex_id.y) %>%
  rename(hex_id = hex_id.x)
```

```{r}
tm_shape(hex_grid_sf) +
  tm_fill("weekday_afternoon_trips", 
          style = "quantile", 
          palette = "Blues",
          title = "Passenger trips") +
  tm_layout(main.title = "Weekday Afternoon Peak Passenger Trips",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2) +
  tm_credits("Source: LTA DataMall", position = c("left", "bottom"))
```

### Weekend Morning Peak

```{r}
weekend_morning_trips <- busstop_hex %>%
  inner_join(weekend_morning_peak, by = c("BUS_STOP_N" = "ORIGIN_PT_CODE"))
```

```{r}
duplicate <- weekend_morning_trips %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
glimpse(duplicate)
```

```{r}
hex_weekend_morning <- weekend_morning_trips %>%
  group_by(hex_id) %>%
  summarise(weekend_morning_trips = sum(TRIPS, na.rm = TRUE))
```

```{r}
hex_grid_sf <- hex_grid_sf %>%
    st_join(hex_weekend_morning, by = "hex_id")

hex_grid_sf <- hex_grid_sf %>%
  select(-hex_id.y) %>%
  rename(hex_id = hex_id.x)
```

```{r}
tm_shape(hex_grid_sf) +
  tm_fill("weekend_morning_trips", 
          style = "quantile", 
          palette = "Blues",
          title = "Passenger trips") +
  tm_layout(main.title = "Weekend Morning Peak Passenger Trips",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2) +
  tm_credits("Source: LTA DataMall", position = c("left", "bottom"))
```

### Weekend Evening Peak

```{r}
weekend_evening_trips <- busstop_hex %>%
  inner_join(weekend_evening_peak, by = c("BUS_STOP_N" = "ORIGIN_PT_CODE"))
```

```{r}
duplicate <- weekend_evening_trips %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
glimpse(duplicate)
```

```{r}
hex_weekend_evening <- weekend_evening_trips %>%
  group_by(hex_id) %>%
  summarise(weekend_evening_trips = sum(TRIPS, na.rm = TRUE))
```

```{r}
hex_grid_sf <- hex_grid_sf %>%
    st_join(hex_weekend_evening, by = "hex_id")

hex_grid_sf <- hex_grid_sf %>%
  select(-hex_id.y) %>%
  rename(hex_id = hex_id.x)
```

```{r}
tm_shape(hex_grid_sf) +
  tm_fill("weekend_evening_trips", 
          style = "quantile", 
          palette = "Blues",
          title = "Passenger trips") +
  tm_layout(main.title = "Weekend Evening Peak Passenger Trips",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2) +
  tm_credits("Source: LTA DataMall", position = c("left", "bottom"))
```

```{r}
rm(busstop_hex, hex_weekday_afternoon, hex_weekday_morning, hex_weekend_evening, hex_weekend_morning, weekday_afternoon_peak, weekday_afternoon_trips, weekday_morning_peak, weekday_morning_trips, weekend_evening_peak, weekend_evening_trips, weekend_morning_peak, weekend_morning_trips)
```

## Create a Spatial Weights Matrix

In this case, since contiguity-based weights (which only consider neighboring polygons that share a boundary) might not be appropriate due to the missing observations, distance-based weights could be more suitable. Distance-based weights consider the distance between the centroids of the hexagons to determine neighbors, which can capture spatial relationships even when hexagons are not directly adjacent.

### Fixed Distance Weights

In examining the spatial distribution of passenger trips originating from hexagonal zones, we assume that the influence of any given zone on its neighbors is consistent up to a specific threshold. This assumption is grounded in the regularity of urban transportation patterns, where the effect of a transport node is presumed to reach a limit beyond which it dissipates rapidly due to the availability of alternative nodes. Given the structured nature of urban layouts and the spacing of transport hubs, fixed distance weights provide a clear-cut criterion for delineating the sphere of influence for each zone. This approach allows for a simplified yet robust analysis of spatial autocorrelation, revealing clusters of high and low trip generation that are critical for transport planning and policy interventions.

```{r}
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

The summary report shows that the largest first nearest neighbour distance is 67.5 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.

### Computing Fixed-Distance Weights Matrix

Now, we will compute the distance weight matrix by using *dnearneigh()* as shown in the code chunk below.

```{r}
wm_d68 <- dnearneigh(coords, 0, 68, longlat = TRUE)
wm_d68
```

Next, we will use *str()* to display the content of wm_d68 weight matrix.

```{r}
str(wm_d68)
```

```{r}
n_comp <- n.comp.nb(wm_d68)
table(n_comp$comp.id)
```

```{r}
summary(wm_d68)
```

### **Computing adaptive distance weight matrix**

One of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.

It is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.

```{r}
wm_ad <- hex_grid_sf %>% 
  mutate(nb = st_knn(geometry,
                     k=8),
         wt = st_weights(nb),
               .before = 1)
```

```{r}
str(wm_ad)
```

## **Weights based on IDW**

```{r}
wm_idw <- hex_grid_sf %>%
  mutate(nb = st_contiguity(geometry),
         wts = st_inverse_distance(nb, geometry,
                                   scale = 1,
                                   alpha = 1),
         .before = 1)
```

## Reference

<https://desktop.arcgis.com/zh-cn/arcmap/latest/tools/spatial-statistics-toolbox/h-whyhexagons.htm>

<https://urbandatapalette.com/post/2021-08-tessellation-sf/>
