---
title: "Take-home Exercise 2: Analyzing the Dynamics of Bus Commute Flow and Spatial Interaction in Singapore"
author: "QIU RUILIU"
date: "6 Dec 2023"
date-modified: "last-modified"
format: html
execute: 
  eval: true
  echo: true
  warning: false
editor: visual
---

## **Setting the Scene**

The inquiry focuses on the key motivators prompting city residents to rise early for their daily commutes from home to work, and the consequences of discontinuing public bus services along specific routes. These issues represent significant challenges for transport operators and urban planners.

Traditionally, understanding these dynamics involved conducting extensive commuter surveys. These surveys, however, are expensive, time-intensive, and laborious. Moreover, the data collected often requires extensive processing and analysis, leading to reports that are frequently outdated by the time they are completed.

With the digitalization of urban infrastructure, including public buses, mass rapid transit systems, public utilities, and roads, new opportunities for data collection arise. The integration of pervasive computing technologies like GPS in vehicles and SMART cards among public transport users allows for detailed tracking of movement patterns across time and space.

Despite this, the rapid accumulation of geospatial data has overwhelmed planners' capacity to effectively analyze and convert it into valuable insights. This inefficiency negatively impacts the return on investment in data collection and management.

## **Motivation and Objective**

The purpose of this take-home project is twofold. First, it addresses the gap in applied research demonstrating the integration, analysis, and modeling of the increasingly available open data for effective policy-making. Despite the abundance of such data, there is a noticeable absence of practical studies showcasing its potential use in policy decisions.

Second, the project aims to fill the void in practical research illustrating the application of geospatial data science and analysis (GDSA) in decision-making processes.

Therefore, the assignment involves conducting a case study to showcase the value of GDSA. This will involve synthesizing publicly accessible data from various sources to construct spatial interaction models. These models will be used to identify and analyze factors influencing the urban mobility patterns of public bus transit.

## 1.Getting Started

The code snippet shown is responsible for loading various packages that provide essential tools and functions for the analysis.

```{r}
pacman::p_load(tmap, sf, dplyr, DT, sp,
               stplanr, performance, mapview,
               ggpubr, tidyverse, httr,
               units, reshape2)
```

-   **`pacman::p_load`**: This function from the **`pacman`** package streamlines the process of loading multiple R packages. If a package is not already installed, `p_load` will install it before loading.

-   **`tmap`**: Utilized for creating thematic maps, essential in visualizing geospatial data.

-   **`sf`**: Stands for "simple features" and is used for handling and analyzing geospatial data.

-   **`dplyr`**: A part of the **`tidyverse`** collection, this package is instrumental in data manipulation tasks like filtering, selecting, and summarizing data.

-   **`DT`**: Provides an R interface to the JavaScript library "DataTables", enabling interactive display of data in tables.

-   **`sp`**: Offers classes and methods for spatial data, crucial for handling spatial points, lines, and polygons.

-   **`stplanr`**: Specifically designed for sustainable transport planning with spatial data.

-   **`performance`**: Useful for assessing and comparing the performance of statistical models.

-   **`mapview`**: Facilitates interactive viewing of spatial data in R.

-   **`ggpubr`**: A part of the **`ggplot2`** ecosystem, this package provides additional functions for creating publication-ready plots.

-   **`tidyverse`**: A collection of R packages designed for data science, providing tools for data manipulation, visualization, and more.

-   **`httr`**: Used for working with HTTP protocols to access web resources.

-   **`units`**: Deals with measurement units, crucial for handling and converting between different units of measurement in spatial data.

-   **`reshape2`**: Aids in reshaping data, transitioning between wide and long formats, which is often necessary in data analysis.

Each of these packages plays a specific role in the analysis, ranging from data manipulation and visualization to handling spatial and web-based data.

## 2.Data Importing

### 2.1Geospatial Data Importing

This R code snippet is focused on importing and transforming geospatial data related to Singapore's bus stops and Metropolitan Planning Strategy Zones (MPSZ) for the year 2019. Using `st_read` from the **`sf`** package, it loads the **BusStop** and **MPSZ-2019** layers from a specified directory (**data/geospatial**). Both datasets are then transformed to the local Singapore coordinate reference system (CRS code 3414) using `st_transform`.

```{r}
busstop <- st_read(dsn = "data/geospatial",
                   layer = "BusStop") %>%
  st_transform(crs = 3414)
```

```{r}
mpsz <- st_read(dsn = "data/geospatial",
                   layer = "MPSZ-2019") %>%
  st_transform(crs = 3414)
```

Display and grasp the basic situation of geospatial dataset **mpsz**.

```{r}
mpsz
```

Export and save in **rds** format for later use.

```{r}
mpsz <- write_rds(mpsz, "data/rds/mpsz.rds")
```

### 2.2Aspatial Data Importing

This line of R code is used for importing an aspatial dataset named **origin_destination_bus_202310.csv** from a specified directory (**data/aspatial**). The function `read_csv` from the **`tidyverse`** package efficiently reads the CSV file, converting it into a dataframe. This dataset likely contains origin-destination information for bus routes in October, 2023.

```{r}
odbus <- read_csv("data/aspatial/origin_destination_bus_202310.csv")
```

The `glimpse(odbus)` function provides a quick overview of the structure and contents of the **odbus** dataframe, summarizing its columns, data types, and a few initial entries.

```{r}
glimpse(odbus)
```

This code converts the **ORIGIN_PT_CODE** and **DESTINATION_PT_CODE** columns in the **odbus** dataframe to factors, categorizing unique bus stop codes for analysis.

```{r}
odbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE)
odbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE) 
```

### **2.3Extracting the Study Data**

#### 2.3.1Extracting the Trips Volume of Weekday Morning Peak

This code snippet filters and summarizes the **odbus** dataframe to extract data on bus trips during weekday morning peak hours (6 to 9 AM). It selects records marked as **WEEKDAY**, groups them by origin and destination bus stop codes, and then calculates the total number of trips between each stop pair in this time frame.

```{r}
weekday6_9 <- odbus %>%
  filter(DAY_TYPE == "WEEKDAY") %>%
  filter(TIME_PER_HOUR >= 6 &
           TIME_PER_HOUR <= 9) %>%
  group_by(ORIGIN_PT_CODE,
           DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))
```

The `datatable(weekday6_9)` function creates an interactive table display of the **weekday6_9** dataframe, facilitating easy exploration and analysis of the data.

```{r}
datatable(weekday6_9)
```

The `write_rds(weekday6_9, "data/rds/weekday6_9.rds")` function saves the **weekday6_9** dataframe to a file named **weekday6_9.rds** for future use.

```{r eval=FALSE}
write_rds(weekday6_9, "data/rds/weekday6_9.rds")
```

The `read_rds("data/rds/weekday6_9.rds")` function loads the previously saved **weekday6_9** dataframe back into the R environment.

```{r}
weekday6_9 <- read_rds("data/rds/weekday6_9.rds")
```

#### 2.3.2Extracting the Trips Volume of Weekday Afternoon Peak

Repeat the process above for weekday afternoon peak (5-8 PM).

```{r}
weekday17_20 <- odbus %>%
  filter(DAY_TYPE == "WEEKDAY") %>%
  filter(TIME_PER_HOUR >= 17 &
           TIME_PER_HOUR <= 20) %>%
  group_by(ORIGIN_PT_CODE,
           DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))
```

```{r}
datatable(weekday17_20)
```

```{r eval=FALSE}
write_rds(weekday17_20, "data/rds/weekday17_20.rds")
```

```{r}
weekday17_20 <- read_rds("data/rds/weekday17_20.rds")
```

#### 2.3.3Extracting the Trips Volume of Weekend/Holiday Morning Peak

Repeat the process above for weekend/holiday morning peak (11 AM-2 PM).

```{r}
weekend11_14 <- odbus %>%
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  filter(TIME_PER_HOUR >= 11 &
           TIME_PER_HOUR <= 14) %>%
  group_by(ORIGIN_PT_CODE,
           DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))
```

```{r}
datatable(weekend11_14)
```

```{r eval=FALSE}
write_rds(weekend11_14, "data/rds/weekend11_14.rds")
```

```{r}
weekend11_14 <- read_rds("data/rds/weekend11_14.rds")
```

#### 2.3.4Extracting the Trips Volume of Weekend/Holiday Evening Peak

Repeat the process above for weekend/holiday evening peak (4-7 PM).

```{r}
weekend16_19 <- odbus %>%
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  filter(TIME_PER_HOUR >= 16 &
           TIME_PER_HOUR <= 19) %>%
  group_by(ORIGIN_PT_CODE,
           DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))
```

```{r}
datatable(weekend16_19)
```

```{r eval=FALSE}
write_rds(weekend16_19, "data/rds/weekend16_19.rds")
```

```{r}
weekend16_19 <- read_rds("data/rds/weekend16_19.rds")
```

## **4.Geospatial Data Wrangling**

### **4.1Combining busstop and mpsz**

The code `st_intersection(busstop, mpsz)` combines the **busstop** and **mpsz** datasets to retain only those bus stops located within the boundaries of Singapore's metropolitan planning zones. The `select(BUS_STOP_N, SUBZONE_C)` part then extracts specific columns, namely bus stop IDs and subzone codes, from the intersected dataset.

```{r}
busstop_mpsz <- st_intersection(busstop, mpsz) %>%
  select(BUS_STOP_N, SUBZONE_C)
```

The `mapview(busstop_mpsz)` function creates an interactive map displaying the spatial data from the **busstop_mpsz** dataframe, visualizing the locations of bus stops within Singapore's planning zones.

```{r}
mapview(busstop_mpsz)
```

### 4.2Creating Hexagon Layer

The code `st_make_grid(mpsz, cellsize = 2 * 375 / sqrt(3), square = FALSE)` generates a hexagonal grid overlay on the **mpsz** spatial data. Each hexagon in the grid has a perpendicular distance from its center to its edges of 375 meters, effectively creating a hexagonal pattern to represent [Traffic Analysis Zones (TAZs)](https://tmg.utoronto.ca/files/Reports/Traffic-Zone-Guidance_March-2021_Final.pdf).

```{r}
hex_grid <- st_make_grid(mpsz, cellsize = 2 * 375 / sqrt(3), square = FALSE)
```

This code converts the **hex_grid** object into a simple features (sf) dataframe **hex_grid_sf**, and then adds a new column **hex_id** that assigns a unique identifier to each hexagon in the grid.

```{r}
hex_grid_sf <- st_sf(geometry = hex_grid) %>%
  mutate(hex_id = 1:length(hex_grid))
```

This code calculates the number of bus stops within each hexagon of the **hex_grid_sf** grid. It uses `st_intersects` to identify which bus stops (**busstop_mpsz**) fall within each hexagon, and then applies a function to count these stops for each hexagon, handling any missing values (`na.rm = TRUE`).

```{r}
busstop_counts <- st_intersects(hex_grid_sf, busstop_mpsz, sparse = FALSE) %>% 
  apply(1, function(x) sum(x, na.rm = TRUE))
```

This step assigns the computed bus stop counts (`busstop_counts`) to a new column `bus_stop_count` in the **hex_grid_sf** dataframe, effectively adding the number of bus stops within each hexagon to the grid data.

```{r}
hex_grid_sf$bus_stop_count <- busstop_counts
```

This code filters the **hex_grid_sf** dataframe to keep only those hexagons that have one or more bus stops, effectively removing hexagons with no bus stop presence.

```{r}
hex_grid_sf <- hex_grid_sf %>%
  filter(bus_stop_count > 0)
```

This code creates a visual map in R using the **`tmap`** package. It overlays hexagons from **hex_grid_sf** onto the **mpsz** spatial layout, coloring them based on the count of bus stops in each hexagon. The map features a legend, titles, and styling details for clarity and visual appeal. The final map displays the distribution of bus stops across Singapore, with additional borders for context and credits for data sources.

```{r}
tmap_options(check.and.fix = TRUE)
map_hexagon <- tm_shape(hex_grid_sf) +
  tm_polygons(
    col = "bus_stop_count",
    palette = "Purples",
    style = "cont",
    title = "Number of Bus Stops",
    id = "hex_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.vars = c("Number of Bus Stops" = "bus_stop_count"),
    popup.format = list(bus_stop_count = list(format = "f", digits = 0))
  ) +
  tm_shape(mpsz) + 
  tm_borders(col = "grey75", lwd = 0.7) +
  tm_layout(
    main.title = "Bus Stop Distribution in Singapore",
    main.title.size = 1.5,
    legend.title.size = 1,
    legend.text.size = 0.8,
    legend.position = c("left", "bottom"),
    frame = FALSE,
    inner.margins = c(0.05, 0.05, 0.05, 0.05)
  ) +
  tm_credits("Data Source: LTA DataMall, Data.gov.sg", position = c("RIGHT", "BOTTOM"), size = 0.8) +
  tm_view(view.legend.position = c("left", "bottom"))

map_hexagon
```

[Observations from the map:]{.underline}

-   Blank Areas: The absence of hexagons in certain parts of the map suggests these are areas with no bus stops. These could be non-residential areas, such as industrial zones, green spaces, or water bodies where public bus services are not necessary or practical.

-   Bus Stop-Dense Areas: Regions densely packed with hexagons indicate a high concentration of bus stops. These areas are likely to be highly urbanized with significant residential and commercial activities, necessitating a greater number of bus stops to accommodate the public transport needs of the population.

The distribution pattern reflects the urban planning and public transportation infrastructure of Singapore, designed to cater to areas with high commuter demand while excluding zones where bus stops are not viable.

### 4.3Correspondence of Hexagon and Bus Stop ID

The code creates a new dataset **busstop_hex** by intersecting **busstop** locations with the **hex_grid_sf** to assign a **hex_id** to each bus stop. It then selects the bus stop number and corresponding **hex_id**, and removes the spatial geometry data for a simple reference table. The final step omits any entries with missing values to ensure a clean dataset for merging with other data based on hexagon and bus stop IDs.

```{r}
busstop_hex <- st_intersection(busstop, hex_grid_sf) %>%
  select(BUS_STOP_N, hex_id) %>%
  st_drop_geometry()
```

```{r}
busstop_hex <- na.omit(busstop_hex)
```

The `head(busstop_hex)` function displays the first few rows of the **busstop_hex** dataframe for a quick preview of its structure and data.

```{r}
head(busstop_hex)
```

Export and save **busstop_hex** in rds format for future use.

```{r}
write_rds(busstop_hex, "data/rds/busstop_hex.rds")  
```

Remove items no longer needed from R environment to free memory and avoid redundancy.

```{r}
rm(hex_grid, map_hexagon, odbus, busstop_counts)
```

## 5.Preparing Commute Flow Data

### 5.1Weekday Morning Peak Flow

The code merges flow data from **weekday6_9** with bus stop IDs from **busstop_hex** based on common origin bus stop numbers, then renames the key columns for clarity, assigning hex IDs to origin points and preserving destination bus stop codes.

```{r eval=FALSE}
weekday_morning_od <- left_join(weekday6_9 , busstop_hex,
            by = c("ORIGIN_PT_CODE" = "BUS_STOP_N")) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_HEX = hex_id,
         DESTIN_BS = DESTINATION_PT_CODE)
```

Before continue, it is a good practice for us to check for duplicating records (It can be judged based on data frame is blank or not).

```{r eval=FALSE}
duplicate <- weekday_morning_od %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

If duplicated records are found, the code chunk below will be used to retain the unique records.

```{r eval=FALSE}
weekday_morning_od <- unique(weekday_morning_od)
```

This code further enhances the **weekday_morning_od** dataframe by joining it with the **busstop_hex** dataframe to append **hex_id** information corresponding to the destination bus stops, linking each trip's endpoint to its respective hexagonal spatial zone.

```{r eval=FALSE}
weekday_morning_od <- left_join(weekday_morning_od , busstop_hex,
            by = c("DESTIN_BS" = "BUS_STOP_N"))
```

```{r eval=FALSE}
duplicate <- weekday_morning_od %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

```{r eval=FALSE}
weekday_morning_od <- unique(weekday_morning_od)
```

This step renames the destination hex ID column for clarity, removes any rows with missing data, then groups the data by origin and destination hex IDs, and summarizes it to calculate the total number of trips made during the weekday morning peak hours between each hexagon pair.

```{r eval=FALSE}
weekday_morning_od <- weekday_morning_od %>%
  rename(DESTIN_HEX = hex_id) %>%
  drop_na() %>%
  group_by(ORIGIN_HEX, DESTIN_HEX) %>%
  summarise(WEEKDAY_MORNING_PEAK = sum(TRIPS))
```

It is time to save the output into an rds file format.

```{r eval=FALSE}
write_rds(weekday_morning_od, "data/rds/weekday_morning_od.rds")
```

```{r}
weekday_morning_od <- read_rds("data/rds/weekday_morning_od.rds")
```

### 5.2Weekday Afternoon Peak Flow

Repeat the process above for weekday afternoon peak (5-8 PM).

```{r eval=FALSE}
weekday_afternoon_od <- left_join(weekday17_20 , busstop_hex,
            by = c("ORIGIN_PT_CODE" = "BUS_STOP_N")) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_HEX = hex_id,
         DESTIN_BS = DESTINATION_PT_CODE)
```

```{r eval=FALSE}
duplicate <- weekday_afternoon_od %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

```{r eval=FALSE}
weekday_afternoon_od <- unique(weekday_afternoon_od)
```

```{r eval=FALSE}
weekday_afternoon_od <- left_join(weekday_afternoon_od , busstop_hex,
            by = c("DESTIN_BS" = "BUS_STOP_N"))
```

```{r eval=FALSE}
duplicate <- weekday_afternoon_od %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

```{r eval=FALSE}
weekday_afternoon_od <- unique(weekday_afternoon_od)
```

```{r eval=FALSE}
weekday_afternoon_od <- weekday_afternoon_od %>%
  rename(DESTIN_HEX = hex_id) %>%
  drop_na() %>%
  group_by(ORIGIN_HEX, DESTIN_HEX) %>%
  summarise(WEEKDAY_AFTERNOON_PEAK = sum(TRIPS))
```

```{r eval=FALSE}
write_rds(weekday_afternoon_od, "data/rds/weekday_afternoon_od.rds")
```

```{r}
weekday_afternoon_od <- read_rds("data/rds/weekday_afternoon_od.rds")
```

### 5.3Weekend Morning Peak Flow

Repeat the process above for weekend/holiday morning peak (11 AM-2 PM).

```{r eval=FALSE}
weekend_morning_od <- left_join(weekend11_14 , busstop_hex,
            by = c("ORIGIN_PT_CODE" = "BUS_STOP_N")) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_HEX = hex_id,
         DESTIN_BS = DESTINATION_PT_CODE)
```

```{r eval=FALSE}
duplicate <- weekend_morning_od %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

```{r eval=FALSE}
weekend_morning_od <- unique(weekend_morning_od)
```

```{r eval=FALSE}
weekend_morning_od <- left_join(weekend_morning_od , busstop_hex,
            by = c("DESTIN_BS" = "BUS_STOP_N"))
```

```{r eval=FALSE}
duplicate <- weekend_morning_od %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

```{r eval=FALSE}
weekend_morning_od <- unique(weekend_morning_od)
```

```{r eval=FALSE}
weekend_morning_od <- weekend_morning_od %>%
  rename(DESTIN_HEX = hex_id) %>%
  drop_na() %>%
  group_by(ORIGIN_HEX, DESTIN_HEX) %>%
  summarise(WEEKEND_MORNING_PEAK = sum(TRIPS))
```

```{r eval=FALSE}
write_rds(weekend_morning_od, "data/rds/weekend_morning_od.rds")
```

```{r}
weekend_morning_od <- read_rds("data/rds/weekend_morning_od.rds")
```

### 5.4Weekend Evening Peak Flow

Repeat the process above for weekend/holiday evening peak (4-7 PM).

```{r eval=FALSE}
weekend_evening_od <- left_join(weekend16_19 , busstop_hex,
            by = c("ORIGIN_PT_CODE" = "BUS_STOP_N")) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_HEX = hex_id,
         DESTIN_BS = DESTINATION_PT_CODE)
```

```{r eval=FALSE}
duplicate <- weekend_evening_od %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

```{r eval=FALSE}
weekend_evening_od <- unique(weekend_evening_od)
```

```{r eval=FALSE}
weekend_evening_od <- left_join(weekend_evening_od , busstop_hex,
            by = c("DESTIN_BS" = "BUS_STOP_N"))
```

```{r eval=FALSE}
duplicate <- weekend_evening_od %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

```{r eval=FALSE}
weekend_evening_od <- unique(weekend_evening_od)
```

```{r eval=FALSE}
weekend_evening_od <- weekend_evening_od %>%
  rename(DESTIN_HEX = hex_id) %>%
  drop_na() %>%
  group_by(ORIGIN_HEX, DESTIN_HEX) %>%
  summarise(WEEKEND_EVENING_PEAK = sum(TRIPS))
```

```{r eval=FALSE}
write_rds(weekend_evening_od, "data/rds/weekend_evening_od.rds")
```

```{r}
weekend_evening_od <- read_rds("data/rds/weekend_evening_od.rds")
```

Remove items no longer needed to free memory and avoid redundancy.

```{r}
rm(weekday6_9, weekday17_20, weekend11_14, weekend16_19)
```

## **6.Visualising Commute Flow**

### **6.1Removing Intra-zonal Flows**

The code filters out intra-zonal flows from four separate data frames by excluding rows where the origin hexagon (**ORIGIN_HEX**) is the same as the destination hexagon (**DESTIN_HEX**). This step is crucial for analysis as it removes trips that start and end within the same traffic analysis zone, focusing the study on inter-zonal movements which are more significant for understanding commuting patterns and the broader transportation network efficiency.

```{r}
weekday_morning_od1 <- weekday_morning_od[weekday_morning_od$ORIGIN_HEX!=weekday_morning_od$DESTIN_HEX,]
```

```{r}
weekday_afternoon_od1 <- weekday_afternoon_od[weekday_afternoon_od$ORIGIN_HEX!=weekday_afternoon_od$DESTIN_HEX,]
```

```{r}
weekend_morning_od1 <- weekend_morning_od[weekend_morning_od$ORIGIN_HEX!=weekend_morning_od$DESTIN_HEX,]
```

```{r}
weekend_evening_od1 <- weekend_evening_od[weekend_evening_od$ORIGIN_HEX!=weekend_evening_od$DESTIN_HEX,]
```

### 6.2Creating the Desire Lines

The code uses the `od2line` function to transform the inter-zonal flow data from each time period into **desire lines**, which are spatial representations of the volume and direction of trips between different hexagons. These lines are prepared for visualization, allowing us to graphically depict and analyze commuting patterns for different times of the day and week on a map.

```{r}
weekday_morning_flowLine <- od2line(flow = weekday_morning_od1, 
                    zones = hex_grid_sf,
                    zone_code = "hex_id")
```

```{r}
weekday_afternoon_flowLine <- od2line(flow = weekday_afternoon_od1, 
                    zones = hex_grid_sf,
                    zone_code = "hex_id")
```

```{r}
weekend_morning_flowLine <- od2line(flow = weekend_morning_od1, 
                    zones = hex_grid_sf,
                    zone_code = "hex_id")
```

```{r}
weekend_evening_flowLine <- od2line(flow = weekend_evening_od1, 
                    zones = hex_grid_sf,
                    zone_code = "hex_id")
```

### 6.3Visualising the Desire Lines

#### 6.3.1Weekday Morning Peak Commute Flow Map

This visualization code uses the **`tmap`** package to plot the hexagonal grid as a base, draws the boundaries of the metropolitan planning zones (MPZ), and overlays the **desire lines** representing high-volume weekday morning commute flows in Singapore. The lines are styled to vary in width and color intensity based on the volume of commutes, with thicker, darker lines indicating higher numbers of trips.

```{r}
tm_shape(hex_grid_sf) +
  tm_polygons(
    border.col = "grey50", 
    border.alpha = 0.6, 
    alpha = 0.1
  ) +
  tm_shape(weekday_morning_flowLine %>% 
             filter(WEEKDAY_MORNING_PEAK >= 5000)) +
  tm_lines(
    lwd = "WEEKDAY_MORNING_PEAK",
    style = "quantile",
    scale = c(0.1, 1, 3, 5, 7, 10),
    n = 6,
    alpha = 0.5,
    palette = "Blues"
  ) +
  tm_shape(mpsz) +
  tm_borders(
    col = "darkblue", 
    alpha = 0.1,
    lwd = 1.5
  ) +
  tm_layout(
    main.title = "Weekday Morning Commute Flows in Singapore",
    main.title.position = "center",
    main.title.size = 1.0,
    legend.title.size = 0.8,
    legend.text.size = 0.7,
    legend.position = c("left", "bottom"),
    frame = FALSE,
    inner.margins = c(0.05, 0.05, 0.05, 0.05)
  ) +
  tm_credits("Source: LTA DataMall", position = c("RIGHT", "BOTTOM"), size = 0.5)
```

[Insight from the Map:]{.underline}

The "Weekday Morning Commute Flows in Singapore" map reveals significant commuter traffic between various regions during peak morning hours. The thicker, darker lines suggest heavy flow between central business districts and outlying residential areas, indicating a typical urban commute pattern where many residents travel towards city centers for work. Areas with dense hexagon clusters, likely representing central and suburban residential zones, show extensive outward flow, highlighting these as key commuter hubs. Conversely, some regions exhibit sparse lines, suggesting lower population density or less reliance on public bus transit.

#### 6.3.2Weekday Afternoon Peak Commute Flow Map

```{r}
tm_shape(hex_grid_sf) +
  tm_polygons(
    border.col = "grey50", 
    border.alpha = 0.6, 
    alpha = 0.1
  ) +
  tm_shape(weekday_afternoon_flowLine %>% 
             filter(WEEKDAY_AFTERNOON_PEAK >= 5000)) +
  tm_lines(
    lwd = "WEEKDAY_AFTERNOON_PEAK",
    style = "quantile",
    scale = c(0.1, 1, 3, 5, 7, 10),
    n = 6,
    alpha = 0.5,
    palette = "Blues"
  ) +
  tm_shape(mpsz) +
  tm_borders(
    col = "darkblue", 
    alpha = 0.1,
    lwd = 1.5
  ) +
  tm_layout(
    main.title = "Weekday Afternoon Commute Flows in Singapore",
    main.title.position = "center",
    main.title.size = 1.0,
    legend.title.size = 0.8,
    legend.text.size = 0.7,
    legend.position = c("left", "bottom"),
    frame = FALSE,
    inner.margins = c(0.05, 0.05, 0.05, 0.05)
  ) +
  tm_credits("Source: LTA DataMall", position = c("RIGHT", "BOTTOM"), size = 0.5)
```

[Insight from the Map:\
]{.underline}The "Weekday Afternoon Commute Flows in Singapore" map suggests a reverse commute pattern from the morning, with significant flows from central areas to the outskirts, likely as people return home from work. The dense lines indicate high traffic volumes, particularly from the CBD and other employment hubs to residential districts. The distribution and volume of these lines can indicate areas with a high demand for evening public transportation services, and such insights could inform enhancements to bus service capacity and frequency to meet commuter needs during peak hours.

#### 6.3.3Weekend Morning Peak Commute Flow Map

```{r}
tm_shape(hex_grid_sf) +
  tm_polygons(
    border.col = "grey50", 
    border.alpha = 0.6, 
    alpha = 0.1
  ) +
  tm_shape(weekend_morning_flowLine %>% 
             filter(WEEKEND_MORNING_PEAK >= 3000)) +
  tm_lines(
    lwd = "WEEKEND_MORNING_PEAK",
    style = "quantile",
    scale = c(0.1, 1, 3, 5, 7, 13, 15),
    n = 7,
    alpha = 0.5,
    palette = "Blues"
  ) +
  tm_shape(mpsz) +
  tm_borders(
    col = "darkblue", 
    alpha = 0.1,
    lwd = 1.5
  ) +
  tm_layout(
    main.title = "Weekend Morning Commute Flows in Singapore",
    main.title.position = "center",
    main.title.size = 1.0,
    legend.title.size = 0.8,
    legend.text.size = 0.7,
    legend.position = c("left", "bottom"),
    frame = FALSE,
    inner.margins = c(0.05, 0.05, 0.05, 0.05)
  ) +
  tm_credits("Source: LTA DataMall", position = c("RIGHT", "BOTTOM"), size = 0.5)
```

[Insight from the Map:]{.underline}

The "Weekend Morning Commute Flows in Singapore" map shows a noticeable reduction in volume and fewer dense flow lines compared to weekdays, reflecting a typical decrease in commuting activity during weekends. The flows that are present may indicate travel to weekend-specific destinations like markets, recreational areas, or places of worship. The patterns suggest that the weekend movement is more dispersed and possibly oriented towards leisure or non-work-related activities, contrasting the concentrated, work-directed flows of weekday mornings.

#### 6.3.4Weekend Evening Peak Commute Flow Map

```{r}
tm_shape(hex_grid_sf) +
  tm_polygons(
    border.col = "grey50", 
    border.alpha = 0.6, 
    alpha = 0.1
  ) +
  tm_shape(weekend_evening_flowLine %>% 
             filter(WEEKEND_EVENING_PEAK >= 3000)) +
  tm_lines(
    lwd = "WEEKEND_EVENING_PEAK",
    style = "quantile",
    scale = c(0.1, 1, 3, 5, 7, 10),
    n = 6,
    alpha = 0.5,
    palette = "Blues"
  ) +
  tm_shape(mpsz) +
  tm_borders(
    col = "darkblue", 
    alpha = 0.1,
    lwd = 1.5
  ) +
  tm_layout(
    main.title = "Weekend Evening Commute Flows in Singapore",
    main.title.position = "center",
    main.title.size = 1.0,
    legend.title.size = 0.8,
    legend.text.size = 0.7,
    legend.position = c("left", "bottom"),
    frame = FALSE,
    inner.margins = c(0.05, 0.05, 0.05, 0.05)
  ) +
  tm_credits("Source: LTA DataMall", position = c("RIGHT", "BOTTOM"), size = 0.5)
```

[Insight from the Map:]{.underline}\
The "Weekend Evening Commute Flows in Singapore" map likely indicates an increase in volume compared to the morning, with more pronounced traffic flows towards residential areas and perhaps popular evening destinations. This contrasts with weekday evenings, where the flow would primarily be homeward from work centers. The patterns may suggest leisure and social activities are influencing travel, with possibly greater flows to entertainment or dining hubs and a more dispersed pattern as people return from various activities across the city.

```{r}
rm(duplicate, weekday_morning_flowLine, weekday_morning_od, weekday_morning_od1,
   weekend_morning_flowLine, weekend_morning_od, weekend_morning_od1,
   weekend_evening_flowLine, weekend_evening_od, weekend_evening_od1)
```

## 7.Attractiveness Factors

*In the subsequent section, we will delve into a targeted analysis of the weekday afternoon peak period. The reason for this focus stems from the comprehensive nature of commute drivers during this time. On weekday afternoons, residents are not only heading home from work or school but often transition to leisure activities such as shopping or entertainment venues directly. This complexity presents a rich tapestry of commuting patterns worthy of in-depth examination.*

### 7.1Entertainment Distribution Integration

Entertainment distribution is considered an attractiveness factor because these venues often draw people to travel to them, influencing commuting and traffic flows. The provided code reads in the **entertn** geospatial data and then calculates the count of entertainment venues within each hexagon of the **hex_grid_sf** grid, integrating this data to quantify the level of entertainment-related attractiveness of different areas.

```{r}
entertn <- st_read(dsn = "data/geospatial",
                      layer = "entertn")
```

```{r}
hex_grid_sf$entertn_count <- lengths(st_intersects(hex_grid_sf, entertn))
```

### 7.2Food & Beverage Distribution Integration

Food and beverage (F&B) venues act as attractiveness factors because they are destinations that people may frequently visit after work, thus influencing traffic and transportation patterns within an area.

```{r}
FB <- st_read(dsn = "data/geospatial",
                   layer = "F&B")
```

```{r}
hex_grid_sf$FB_count <- lengths(st_intersects(hex_grid_sf, FB))
```

### 7.3Leisure & Recreation Distribution Integration

Leisure and recreation spots are included in the study of weekday afternoon peak times because they are popular destinations that contribute to the flow of people and the overall demand for transportation services during these periods.

```{r}
lere <- st_read(dsn = "data/geospatial",
                   layer = "Liesure&Recreation")
```

```{r}
hex_grid_sf$lere_count <- lengths(st_intersects(hex_grid_sf, lere))
```

### 7.4Retail Distribution Integration

Retail locations are included in the analysis because they are key destinations that attract shoppers, impacting people's movement and transit patterns, especially during peak times.

```{r}
retail <- st_read(dsn = "data/geospatial",
                  layer = "Retails")
```

```{r}
hex_grid_sf$retail_count <- lengths(st_intersects(hex_grid_sf, retail))
```

### 7.5Train Exits Distribution Integration

```{r}
trainexits <- st_read(dsn = "data/geospatial",
                      layer = "Train_Station_Exit_Layer")
```

The code transforms the coordinates of train exit locations to match the coordinate reference system of the hexagonal grid and then counts the number of train exits within each hexagon. This reflects the influence of proximity to train stations on bus ridership, as people often use buses to access MRT stations in Singapore.

```{r}
trainexits <- st_transform(trainexits, st_crs(hex_grid_sf))
hex_grid_sf$trainexits_count <- lengths(st_intersects(hex_grid_sf, trainexits))
```

### 7.6Residence Distribution Integration

The code reads a CSV file containing housing data (**hdb.csv**), filters for entries marked as residential (**Y**), selects columns for latitude, longitude, and total dwelling units, and removes any rows with missing data. This prepares a dataset of residential locations and their capacity, which is important for analyzing homebound travel patterns.

```{r}
hdb <- read_csv("data/aspatial/hdb.csv")
```

```{r}
residential <- hdb %>%
  filter(residential == "Y") %>%
  select(lat, lng, total_dwelling_units) %>%
  na.omit()
```

```{r}
residential <- st_as_sf(residential, 
                           coords = c("lng", "lat"), 
                           crs = 4326) %>%
  st_transform(crs = st_crs(hex_grid_sf))
```

```{r}
intersections <- st_intersects(hex_grid_sf, residential, sparse = TRUE)
hex_grid_sf$residential_count <- mapply(function(index, residential) {
  sum(residential$total_dwelling_units[index], na.rm = TRUE)
}, intersections, MoreArgs = list(residential = residential))
```

```{r}
rm(intersections)
```

## 8.Propulsive Factors

### 8.1Business Distribution Integration

```{r}
business <- st_read(dsn = "data/geospatial",
                      layer = "Business")
```

```{r}
hex_grid_sf$business_count <- lengths(st_intersects(hex_grid_sf, business))
```

### 8.2School Distribution Integration

```{r}
url<-"https://www.onemap.gov.sg/api/common/elastic/search"

csv<-read_csv("data/aspatial/Generalinformationofschools.csv")
postcodes<-csv$`postal_code`

found<-data.frame()
not_found<-data.frame()

for(postcode in postcodes){
  query<-list('searchVal'=postcode,'returnGeom'='Y','getAddrDetails'='Y','pageNum'='1')
  res<- GET(url,query=query)
  
  if((content(res)$found)!=0){
    found<-rbind(found,data.frame(content(res))[4:13])
  } else{
    not_found = data.frame(postcode)
  }
}
```

```{r}
merged = merge(csv, found, by.x = 'postal_code', by.y = 'results.POSTAL', all = TRUE)
write.csv(merged, file = "data/aspatial/schools.csv")
write.csv(not_found, file = "data/aspatial/not_found.csv")
```

```{r}
schools <- read_csv("data/aspatial/schools.csv") %>%
  rename(latitude = "results.LATITUDE",
         longitude = "results.LONGITUDE")%>%
  select(postal_code, school_name, latitude, longitude)
```

```{r}
schools <- schools %>%
  filter(!is.na(longitude) & !is.na(latitude)) %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) %>%
  st_transform(crs = 3414)
```

```{r}
hex_grid_sf$school_count <- lengths(st_intersects(hex_grid_sf, schools))
```

```{r}
rm(csv, found, merged, not_found, query, res,
   postcode, postcodes, url)
```

### 8.3Financial Service Distribution Integration

```{r}
finserv <- st_read(dsn = "data/geospatial",
                      layer = "FinServ")
```

```{r}
hex_grid_sf$finserv_count <- lengths(st_intersects(hex_grid_sf, finserv))
```

### 8.4Final Check of Integrated Data

```{r}
datatable(hex_grid_sf)
```

## 9.Computing Distance Matrix

### **9.1Converting from sf data.table to SpatialPolygonsDataFrame**

```{r}
hex_grid_sp <- as(hex_grid_sf, "Spatial")
hex_grid_sp
```

### **9.2 Computing the Distance Matrix**

```{r}
dist <- spDists(hex_grid_sp, 
                longlat = FALSE)
head(dist, n=c(10, 10))
```

### **9.3Labeling Column and Row Headers of a Distance Matrix**

```{r}
hex_names <- hex_grid_sf$hex_id
```

```{r}
colnames(dist) <- paste0(hex_names)
rownames(dist) <- paste0(hex_names)
```

### **9.4Pivoting Distance Value by HEX_ID**

```{r}
distPair <- melt(dist) %>%
  rename(dist = value)
head(distPair, 10)
```

### **9.5Updating Intra-zonal Distances**

```{r}
distPair %>%
  filter(dist > 0) %>%
  summary()
```

```{r}
distPair$dist <- ifelse(distPair$dist == 0,
                        200, distPair$dist)
```

```{r}
distPair %>%
  summary()
```

```{r}
distPair <- distPair %>%
  rename(orig = Var1,
         dest = Var2)
```

```{r}
write_rds(distPair, "data/rds/distPair.rds") 
```

## 10.Creating Complete Data for Spatial Interaction Modeling

```{r}
weekday_afternoon_od1$ORIGIN_HEX <- as.factor(weekday_afternoon_od1$ORIGIN_HEX)
weekday_afternoon_od1$DESTIN_HEX <- as.factor(weekday_afternoon_od1$DESTIN_HEX)
distPair$orig <- as.factor(distPair$orig)
distPair$dest <- as.factor(distPair$dest)
```

```{r}
weekday_afternoon_od2 <- weekday_afternoon_od1 %>%
  left_join (distPair,
             by = c("ORIGIN_HEX" = "orig",
                    "DESTIN_HEX" = "dest"))
```

```{r}
hex_grid_df <- as.data.frame(hex_grid_sf) %>%
  select(hex_id, bus_stop_count, business_count, school_count, finserv_count, 
         entertn_count, FB_count, lere_count, retail_count, trainexits_count, residential_count) %>%
  mutate(hex_id = as.character(hex_id))
```

```{r}
origin_factors <- hex_grid_df %>%
  select(hex_id, bus_stop_count, business_count, school_count, finserv_count)
weekday_afternoon_od2 <- weekday_afternoon_od2 %>%
  mutate(ORIGIN_HEX = as.character(ORIGIN_HEX),
         DESTIN_HEX = as.character(DESTIN_HEX))
```

```{r}
weekday_afternoon_od2_with_origin <- weekday_afternoon_od2 %>%
  left_join(origin_factors, by = c("ORIGIN_HEX" = "hex_id"))
```

```{r}
destin_factors <- hex_grid_df %>%
  select(hex_id, entertn_count, FB_count, lere_count, retail_count, trainexits_count, residential_count)
```

```{r}
weekday_afternoon_od2_complete <- weekday_afternoon_od2_with_origin %>%
  left_join(destin_factors, by = c("DESTIN_HEX" = "hex_id"))
```

```{r}
glimpse(weekday_afternoon_od2_complete)
```

```{r}
write_rds(weekday_afternoon_od2_complete, "data/rds/SIM_data.rds")
```

```{r}
rm(business, busstop, busstop_hex, busstop_mpsz, destin_factors, dist, distPair, entertn, FB, finserv, hdb, hex_grid_df, hex_grid_sf, hex_grid_sp, lere, mpsz, origin_factors, residential, retail, schools, trainexits, weekday_afternoon_flowLine, weekday_afternoon_od, weekday_afternoon_od1, weekday_afternoon_od2, weekday_afternoon_od2_complete, weekday_afternoon_od2_with_origin, hex_names)
```

## **11.Calibrating Spatial Interaction Models**

### **11.1Importing the modelling data**

```{r}
SIM_data <- read_rds("data/rds/SIM_data.rds")
```

### **11.2Visualising the dependent variable**

```{r}
ggplot(data = SIM_data,
       aes(x = WEEKDAY_AFTERNOON_PEAK)) +
  geom_histogram()
```

```{r}
ggplot(data = SIM_data,
       aes(x = dist,
           y = WEEKDAY_AFTERNOON_PEAK)) +
  geom_point() +
  geom_smooth(method = lm)
```

```{r}
ggplot(data = SIM_data,
       aes(x = log(dist),
           y = log(WEEKDAY_AFTERNOON_PEAK))) +
  geom_point() +
  geom_smooth(method = lm)
```

### **11.3Checking and Replacing Variables with Zero Values**

```{r}
summary(SIM_data)
```

```{r}
SIM_data$business_count <- ifelse(
  SIM_data$business_count == 0,
  0.99, SIM_data$business_count)
SIM_data$school_count <- ifelse(
  SIM_data$school_count == 0,
  0.99, SIM_data$school_count)
SIM_data$finserv_count <- ifelse(
  SIM_data$finserv_count == 0,
  0.99, SIM_data$finserv_count)
SIM_data$entertn_count <- ifelse(
  SIM_data$entertn_count == 0,
  0.99, SIM_data$entertn_count)
SIM_data$FB_count <- ifelse(
  SIM_data$FB_count == 0,
  0.99, SIM_data$FB_count)
SIM_data$lere_count <- ifelse(
  SIM_data$lere_count == 0,
  0.99, SIM_data$lere_count)
SIM_data$retail_count <- ifelse(
  SIM_data$retail_count == 0,
  0.99, SIM_data$retail_count)
SIM_data$trainexits_count <- ifelse(
  SIM_data$trainexits_count == 0,
  0.99, SIM_data$trainexits_count)
SIM_data$residential_count <- ifelse(
  SIM_data$residential_count == 0,
  0.99, SIM_data$residential_count)
```

```{r}
summary(SIM_data)
```

### **11.4Unconstrained Spatial Interaction Model**

```{r eval=FALSE}
uncSIM <- glm(formula = WEEKDAY_AFTERNOON_PEAK ~ 
                log(bus_stop_count) + 
                log(business_count) +
                log(school_count) +
                log(finserv_count) +
                log(entertn_count) +
                log(FB_count) +
                log(lere_count) +
                log(retail_count) +
                log(trainexits_count) +
                log(residential_count) +
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
write_rds(uncSIM, "data/rds/uncSIM.rds")
```

```{r}
uncSIM <- read_rds("data/rds/uncSIM.rds")
uncSIM
```

### **11.5R-squared Function**

```{r}
CalcRSquared <- function(observed,estimated){
  r <- cor(observed,estimated)
  R2 <- r^2
  R2
}
```

```{r}
CalcRSquared(uncSIM$data$WEEKDAY_AFTERNOON_PEAK, uncSIM$fitted.values)
```

```{r}
r2_mcfadden(uncSIM)
```

### 11.6**Origin Constrained Spatial Interaction Model**

```{r eval=FALSE}
orcSIM <- glm(formula = WEEKDAY_AFTERNOON_PEAK ~
                ORIGIN_HEX +
                log(entertn_count) +
                log(FB_count) +
                log(lere_count) +
                log(retail_count) +
                log(trainexits_count) +
                log(residential_count) +
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
write_rds(orcSIM, "data/rds/orcSIM.rds")
```

```{r}
orcSIM <- read_rds("data/rds/orcSIM.rds")
orcSIM
```

```{r}
CalcRSquared(orcSIM$data$WEEKDAY_AFTERNOON_PEAK, orcSIM$fitted.values)
```

```{r}
r2_mcfadden(orcSIM)
```

### **11.7Destination Constrained Spatial Interaction Model**

```{r eval=FALSE}
decSIM <- glm(formula = WEEKDAY_AFTERNOON_PEAK ~
                DESTIN_HEX +
                log(bus_stop_count) + 
                log(business_count) +
                log(school_count) +
                log(finserv_count) +
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
write_rds(decSIM, "data/rds/decSIM.rds")
```

```{r}
decSIM <- read_rds("data/rds/decSIM.rds")
decSIM
```

```{r}
CalcRSquared(decSIM$data$WEEKDAY_AFTERNOON_PEAK, decSIM$fitted.values)
```

```{r}
r2_mcfadden(decSIM)
```

### 11.8Doubly Constrained Spatial Interaction Model

```{r eval=FALSE}
dbcSIM <- glm(formula = WEEKDAY_AFTERNOON_PEAK ~ 
                ORIGIN_HEX + 
                DESTIN_HEX + 
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
write_rds(dbcSIM, "data/rds/dbcSIM.rds")
```

```{r}
dbcSIM <- read_rds("data/rds/dbcSIM.rds")
dbcSIM
```

```{r}
CalcRSquared(dbcSIM$data$WEEKDAY_AFTERNOON_PEAK, dbcSIM$fitted.values)
```

```{r}
r2_mcfadden(dbcSIM)
```

### 11.9Model Comparison

```{r}
model_list <- list(unconstrained=uncSIM,
                   originConstrained=orcSIM,
                   destinationConstrained=decSIM,
                   doublyConstrained=dbcSIM)
```

```{r}
compare_performance(model_list,
                    metrics = "RMSE")
```

### 11.11Visualizing Fitted

```{r}
df <- as.data.frame(uncSIM$fitted.values) %>%
  round(digits = 0)
```

```{r}
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(uncWEEKDAY_AFTERNOON_PEAK = "uncSIM$fitted.values")
```

```{r}
df <- as.data.frame(orcSIM$fitted.values) %>%
  round(digits = 0)
```

```{r}
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(orcWEEKDAY_AFTERNOON_PEAK = "orcSIM$fitted.values")
```

```{r}
df <- as.data.frame(decSIM$fitted.values) %>%
  round(digits = 0)
```

```{r}
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(decWEEKDAY_AFTERNOON_PEAK = "decSIM$fitted.values")
```

```{r}
df <- as.data.frame(dbcSIM$fitted.values) %>%
  round(digits = 0)
```

```{r}
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(dbcWEEKDAY_AFTERNOON_PEAK = "dbcSIM$fitted.values")
```

```{r}
unc_p <- ggplot(data = SIM_data,
                aes(x = uncWEEKDAY_AFTERNOON_PEAK,
                    y = WEEKDAY_AFTERNOON_PEAK)) +
  geom_point() +
  geom_smooth(method = lm)

orc_p <- ggplot(data = SIM_data,
                aes(x = orcWEEKDAY_AFTERNOON_PEAK,
                    y = WEEKDAY_AFTERNOON_PEAK)) +
  geom_point() +
  geom_smooth(method = lm)

dec_p <- ggplot(data = SIM_data,
                aes(x = decWEEKDAY_AFTERNOON_PEAK,
                    y = WEEKDAY_AFTERNOON_PEAK)) +
  geom_point() +
  geom_smooth(method = lm)

dbc_p <- ggplot(data = SIM_data,
                aes(x = dbcWEEKDAY_AFTERNOON_PEAK,
                    y = WEEKDAY_AFTERNOON_PEAK)) +
  geom_point() +
  geom_smooth(method = lm)

ggarrange(unc_p, orc_p, dec_p, dbc_p,
          ncol = 2,
          nrow = 2)
```
